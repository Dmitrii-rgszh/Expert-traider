Твоя задача — спроектировать и реализовать нейросетевую систему AI-трейдера для Московской биржи, которая:
Основана преимущественно на техническом анализе,
Дополнительно учитывает фундаментальный анализ (в сжатом виде),
Выдаёт торговые сигналы уровня “экстра-профессионального трейдера”,
Регулярно дообучается и подстраивается под каждую конкретную бумагу,
Предоставляет функционал, пригодный для использования в Telegram Miniapp.
Ниже — детальная постановка задачи, которую нужно реализовать.

## Дорожная карта и чек-лист прогресса

| Статус | Блок | Что нужно сделать |
| --- | --- | --- |
| ✅ | Baseline MVP | Подняты rule-based + ruBERT эвристики для новостей, подготовлена таблица trade_labels и базовый RandomForest в ноутбуке. |
| ☐ | Data Foundation (Тех. анализ) | 1) Спроектировать и задокументировать пайплайн выгрузки исторических OHLCV (1m/5m/15m/1h/1d) по всем core-тикерам.<br>2) Настроить Prefect/Airflow-флоу `candles-ingest` с бэкапом в S3/MinIO и валидацией объёмов.<br>3) Добить таблицы `feature_windows/*` для разных таймфреймов (на данный момент хранится только частичный baseline). |
| ✅ | Feature Store v1 | 1) `config/feature_store.yaml` + `docs/feature_store_v1.md` фиксируют схему/версии.<br>2) В `build_window.py` добавлены MACD/ATR/свечные паттерны, снапшоты регистрируются в `train_data_snapshots`.<br>3) `export_snapshots.py` + Prefect таск автоматизируют parquet/feather. |
| ☐ | Labeling & Targets | 1) Формализовать горизонты H (интрадей, swing, позиционный) и параметры TP/SL.<br>2) Добавить расчёт P&L/MaxDrawdown в label-скрипты + quality-метрики (coverage, class balance).<br>3) Визуализировать распределения меток в `notebooks/trade_labels_eda.ipynb` и сохранить отчёт. |
| ☐ | ML Infra (Experimentation) | 1) Развернуть MLflow (или Weights & Biases) для трекинга экспериментов.<br>2) Добавить Makefile/Prefect flow `train-trader-model` с параметрами датасета, диапазонов дат, seed.<br>3) Собирать артефакты моделей в `artifacts/models/{date}/` + сохранять конфиги. |
| ☐ | Baseline Neural Model | 1) Реализовать первую нейросетевую модель (например, Temporal Fusion Transformer) на технических фичах + news scores.<br>2) Настроить k-fold / walk-forward валидацию и метрики (ROC-AUC, Calibrated success rate, expectancy, max drawdown).<br>3) Подготовить inference-скрипт и интеграцию в backend как экспериментальный endpoint. |
| ☐ | Multi-Head “Совет стратегий” | 1) Добавить отдельные головы для тренда / mean-reversion / новостей / волатильности.<br>2) Реализовать meta-агрегатор, который обучается на исторических данных принимать финальное решение.<br>3) Встроить explainability: логировать голоса и топ-фичи. |
| ☐ | Online adaptation & feedback loop | 1) Собрать real-time фидбек пользователей (done ✔️) и подключить его к тренировочному пайплайну.<br>2) Автоматизировать переобучение (например, еженедельно) и деплой новой версии в тестовый контур.<br>3) Добавить мониторинг дрейфа/качества (Prefect + dashboards). |

> Как работать с чек-листом:
> 1. После завершения этапа проставляем ✅ и кратко описываем достижения (дата, ссылка на MR/commit).
> 2. Если этап разбит на подпункты, фиксируем прогресс внутри блока, чтобы не потерять детали.
> 3. Любые промежуточные инсайты (например, проблемы с данными, графики распределений) документируем прямо под таблицей или в отдельном разделе с датой.

### Текущая рабочая фаза (Sprint 0: Data Foundation)

**Цель:** собрать историю свечей/фич, чтобы можно было формировать полноценные датасеты для обучения.

1. **Исторические OHLCV**  
	- [x] Каталог тикеров (core: SBER, GAZP, LKOH, GMKN, ROSN, NVTK, TATN, CHMF, YNDX) в `config/universe_core.json`.  
	- [x] Загрузка 1m/5m/15m/1h/1d через MOEX ISS (`python -m backend.scripts.ingestion.backfill_candles`).  
	- [x] Складирование в таблицу `candles` + parquet (`data/raw/candles/{secid}/{timeframe}/`) — 2024 год выгружен по всем core-тикам (1m…1d) скриптом `backend/scripts/ingestion/backfill_candles.py`, в SQLite `candles` лежит 1.8M+ строк, для каждого тикера создано древо `data/raw/candles/{secid}/{timeframe}/YYYY-MM-DD_*.csv`.

2. **Prefect ingestion flow**  
	- [x] Flow `candles-ingest-flow` с параметрами `secids`, `timeframes`, `since/until`, `export_dir`, `min_ratio`.  
	- [x] Deployment в work pool `local-agent-pool`, расписание каждые 5 минут для 1m/5m, каждые 30 минут для 15m/1h, ежедневно для 1d.  
	- [x] Логирование + алерт по объёму (warning/exception при ratio < threshold).

3. **Feature window генерация v0**  
	- [x] Функция расчёта индикаторов (SMA/EMA, RSI, ATR, volume z-score) в `backend/scripts/features/build_windows.py`.  
	- [x] Запись результатов в `feature_windows`, `feature_numeric` с `feature_set='tech_v0'`.  
	- [x] Экспорт снапшотов в `data/processed/features/{feature_set}/{timeframe}/YYYYMMDD.parquet` (`python -m backend.scripts.features.export_snapshots ...`, интеграция в Prefect flow `candles-and-features-flow`).

4. **Контроль качества данных**  
	- [x] Jupyter-ноутбук `notebooks/data_quality.ipynb` с проверками: количество свечей/день, пропуски, сравнение с отчётом `evaluate_quality`.  
	- [x] Автоматический отчёт в `docs/data_quality/` (JSON + summary) через `python -m backend.scripts.monitoring.data_quality_report ...`.

5. **Документация**  
	- [x] README раздел “Data Foundation” (описание CLI, расписание Prefect, пути raw/processed).  
	- [x] Обновление чек-листа (таблица выше) и фиксация дат выполнения подпунктов (Sprint 0 = done).

### Прогресс на 2025-11-15

- Запущен модуль `backend/scripts/ingestion/news.py`, который ежедневно подтягивает MOEX SiteNews (обработано и записано по 50+ событий за прогон, с заполнением `NewsEvent`, `NewsSource`, `GlobalRiskEvent`, `RiskAlert`).
- Prefect flow `candles-and-features-flow` зарегистрирован через `backend/scripts/scheduler/register_deployments.py`, работает в `local-agent-pool` (1–5-минутные окна) и обслуживается запущенными `prefect server/worker` процессами.
- Запущен `tech_v2` (1m/5m/1h): ресэмплинг с 1m, добавлены признаки Bollinger/Stochastic, снапшоты и отчёты `docs/data_quality/train_snapshots_tech_v2_{1m,1h}.json`.
- Для label_set `intraday_v1` и `swing_v1` сняты EDA (`docs/data_quality/eda_intraday_v1_1m.json`, `docs/data_quality/eda_swing_v1_1h.json`).
- `backend/scripts/ml/prepare_baseline_dataset.py` умеет `--include-news-features`, добавляя счётчики новостей/рисков на окнах 60/240/1440 минут.
- Prefect flow `train-temporal-model-flow` поддерживает grid-search (`--train-grid-json`) и нотификации (`--train-notification-url`).

#### Следующий этап: Baseline Neural Model

1. **Temporal CNN/TFT с news features.** Использовать экспорт `tech_v2` + `--include-news-features`, обучить расширенный Temporal CNN и пилотный Temporal Fusion Transformer; зафиксировать метрики ROC/PR/Expectancy по intraday_v1 и swing_v1.
2. **Grid-search + walk-forward.** Автоматизировать подбор гиперпараметров через `train-temporal-model-flow`, добавить walk-forward split (интервалы 2023→2025) и отчёты в `docs/modeling/baseline_neural_model.md`.
3. **Inference API.** Собрать сервис (`backend/app/ml/service.py`) с эндпоинтом `/api/v1/signals`, который подтягивает последние окна фич, подаёт в обученную модель и возвращает BUY/SELL/HOLD с confidence + текстовым объяснением (top features, news context).

#### Дополнительные доказательства прогресса

- Скрипт `backend/scripts/features/build_window.py` считает SMA/EMA/RSI/volatility/volume z-score и записывает окна в `feature_windows`/`feature_numeric` для `feature_set='tech_v1'`; пайплайн запускается по тикерам SBER/GAZP для периода 2024-10-01 … 2024-11-15.
- Скрипт `backend/scripts/labels/build_labels.py` формирует многогоризонтные метки (`60/240/1440` минут, TP=2%, SL=1%) и публикует их в `trade_labels` c label_set `basic_v1`.
- `backend/scripts/ml/prepare_baseline_dataset.py` собирает объединённый CSV (`data/training/baseline_dataset.csv`) за указанный диапазон; sanity-чек на меньшем окне (2024-10-01) даёт 1.3k строк с 19 столбцами.
- `backend/scripts/training/train_temporal_cnn.py` обучает Temporal CNN (seq=32, batch=64) и сохраняет логи/чекпойнты в `logs/temporal_cnn` (TensorBoard установлен, ROC-построение включено).
- Фикс performance bottleneck: построены композитные индексы `ix_feature_windows_timeframe_feature_set_window_end_secid` и `ix_trade_labels_timeframe_label_set_signal_time_secid` (см. миграцию `0f68bb77f483_add_covering_indexes_for_dataset.py`), `prepare_baseline_dataset.py` переписан на двухфазный селект + join in-memory, из-за чего выгрузка окна 2024-10-01…2024-11-15 (SBER/GAZP, feature_set `tech_v1`, label_set `basic_v1`) занимает ~17 секунд вместо “бесконечного” SQL join.
- Добавлен CLI `backend/scripts/features/export_snapshots.py` + Prefect-задача `export_feature_snapshots_task`, автоматически выгружающие parquet/feather в `data/processed/features/{feature_set}/{timeframe}/YYYYMMDD.parquet`.
- Контроль качества данных реализован через `backend/scripts/monitoring/data_quality_report.py`, отчёты `docs/data_quality/*.json` и ноутбук `notebooks/data_quality.ipynb`; README раздел “Data Foundation” описывает сценарии запуска.
- Создан `config/feature_store.yaml` + `docs/feature_store_v1.md`, снапшоты регистрируются в `train_data_snapshots` (secid/timeframe/feature_set/rows_count).
- `config/label_sets.yaml` + обновлённый `backend/scripts/labels/build_labels.py`: поддержка dry-run, summary JSON (`docs/data_quality/labels_basic_v1_1m_2024-10-01_2024-11-15.json`) и расчёт long/short P&L.
- Prefect flow `train-temporal-model-flow` готовит датасет и запускает `train_temporal_cnn.py` с MLflow-параметрами (`--mlflow-tracking-uri`, `--mlflow-tags` и пр.), автоматически логирует ROC/PR/Accuracy и артефакты.

#### Апдейт 2025-11-15 (intraday_v1 walk-forward)

- Датасет `data/training/dataset_intraday_v1.csv` пересобран для периода 2024-10-01 10:18 UTC – 2024-10-04 18:00 UTC: 17 280 строк, 334 положительных окна (15 — 1 октября, 319 — 3 октября). Включены news features (`--include-news-features`) по окнам 60/240/1440 минут, бэкап лежит в `data/training/dataset_intraday_v1.csv.bak`.
- Walk-forward `configs/walk_forward_intraday.json` обновлён: `train` 10 602/17, `val` 720/182, `test` 5 958/135 строк/позитивов соответственно; маски проверены отдельным sanity-скриптом (см. PowerShell one-liner в history).
- `backend/scripts/training/train_temporal_cnn.py` усилен: `torch.set_float32_matmul_precision("medium")`, автоматический подбор `num_workers` (до 4) + `persistent_workers`, защита чекпойнтов при отсутствии `val`-метрик и форсированное добавление корня репо в `sys.path`/`PYTHONPATH`, чтобы DataLoader-воркеры не падали в Prefect.
- Prefect деплой `train-temporal-model-flow/train-temporal-model-intraday` перерегистрирован с обновлёнными путями и запущен (`flow run kind-ibis`). Флоу завершился успешно, артефакты лежат в `logs/temporal_cnn/tft_split_oct1_balanced` и `artifacts/temporal_cnn/tft_split_oct1_balanced/2024-10-04T22-18`.
- Текущие метрики baseline TFT: `ROC-AUC=0.3532`, `PR-AUC=0.0120`, `precision/recall=0` на тестовом окне (все 99 положительных не найдены). Warning от `sklearn` зафиксирован в логах. Следующий шаг — усилить обучение на классе 1 (class weights, focal loss, downsampling) и перепроверить новостные фичи.

### Фокус после закрытия Sprint 0

1. **Feature Store v2 / расширение признаков.**  
	- Вынести расчёт дополнительных индикаторов в отдельные модули + unit-тесты, описать `tech_v2` и альтернативные таймфреймы (5m/15m/1h) в `config/feature_store.yaml`.  
	- Подготовить materialized views / marts для “feature windows + snapshots” (см. `docs/feature_store_v1.md` → добавить секцию deployment).  
	- Автоматизировать загрузку `train_data_snapshots` в мониторинг (дашборд Prefect + alert при отсутствии новых файлов).

2. **Labeling & Targets расширенный.**  
	- Провести EDA (`notebooks/trade_labels_eda.ipynb`) с новыми P&L-метриками, собрать отчёты по `intraday_v1` и `swing_v1`.  
	- Добавить комбинированные label_set (multi-horizon, meta-label), описать правила в `config/label_sets.yaml`.  
	- Снять качественные метрики (coverage, class balance, expectancy) в JSON и приложить к ML.md.

3. **ML Infra & модельный цикл.**  
	- Подключить MLflow Tracking сервер (docker-compose) и добавить хранение артефактов/ROC фигур в `artifacts/models/{date}/`.  
	- Расширить Prefect `train-temporal-model-flow`: поддержка grid-search (несколько run'ов), публикация метрик в Slack/Telegram.  
	- Подготовить baseline TemporalCNN vs Transformer сравнение + план по A/B в Miniapp.


1. Цели системы и общий функционал
1.1. Главная цель

Создать сервис, который для каждой ликвидной бумаги Мосбиржи и момента времени t:

Формирует торговое решение:

BUY / SELL / HOLD / NO_TRADE,

Даёт параметры сделки:

диапазон входа,

уровни Take Profit / Stop Loss,

уверенность сигнала (0–100),

Даёт объяснение решения в стиле профессионального трейдера,

Учитывает:

техническую картину по бумаге и рынку — главный источник,

фундаментальные факторы — как доп. вес для средне/долгосрока,

новости / триггеры — через отдельный модуль.

1.2. Дополнительный функционал верхнего уровня

Система должна обеспечивать:

Мульти-стратегический “совет директоров”
Несколько виртуальных стратегий:

трендовая (trend following),

контртрендовая (mean reversion),

новостная,

волатильностная.
Каждая даёт своё мнение по сделке, итоговый сигнал — агрегированный.

Детектор рыночного режима
Классификация: тренд вверх/вниз, флэт, паника, эйфория, новостной шторм – с влиянием на сигналы.

Вероятностные сценарии по цене
На заданном горизонте H (дни/часы) система даёт распределение возможных ценовых диапазонов с вероятностями.

Анализ и рекомендации по портфелю пользователя
Для набора позиций:

рекомендации: усилить / держать / сократить / закрыть,

оценка совокупного риска и концентрации.

Анти-тильт и поведенческий анализ пользователя
Анализ поведения пользователя относительно сигналов модели:

нарушения стопов,

“самодеятельные” сделки,

овер-трейдинг.
Формирование предупреждений и регулярных отчётов.

Тренировочный режим “Ты vs AI-трейдер”
Подача исторических сценариев без будущего, сравнение решений пользователя с решениями модели, рейтинг.

Регулярное дообучение

Глобальная модель по всем бумагам,

Локальные адаптеры по каждой бумаге,

Обучение на новых данных и собственных сигналах.

2. Источники данных и их сбор
2.1. Котировки Мосбиржи

Используй MOEX ISS API для получения исторических и текущих данных:

Свечи (OHLCV) по акциям/ETF:

минимум по рынку акций (board TQBR и др. при необходимости),

Индексы:

IMOEX, RTSI, при возможности — отраслевые индексы.

Поддерживаемые таймфреймы (минимум):

1m, 5m, 15m, 1h, 1d.

Сохраняй данные в БД, например:

Таблица candles:

id

secid (тикер)

board

timeframe

datetime

open, high, low, close, volume

2.2. Фундаментальные данные

Фундаментал используется как вспомогательный слой (сильнее влияет на средне- и долгосрок).

Нужно поддерживать (по возможности):

рыночная капитализация,

выручка, прибыль (последние отчётные периоды),

динамика выручки и прибыли,

долговая нагрузка,

дивидендная доходность, история выплат,

базовые мультипликаторы:

P/E, P/B, EV/EBITDA и т.п.

На основе этих данных сформируй агрегированные фундаментальные факторы (см. раздел 3.3).

2.3. Новости и триггеры

Предусмотри интерфейс к отдельному модулю “news-триггеров” (он может быть реализован позже, но интеграция нужна сразу):

Вход: новости с привязкой к бумагам/сектору/рынку, временная отметка.

Выход по каждому тикеру и моменту времени:

news_trigger_score (0–100),

news_direction (−1/0/+1),

news_event_type (санкции, отчётность, дивиденды, M&A, регуляторика и т.д.).

3. Признаки (features)

Основной упор на технические признаки, фундаментал — компактно.

3.1. Технические признаки по каждой бумаге и таймфрейму

Для каждой пары (secid, timeframe, t):

Скользящие средние:

SMA/EMA (например 5, 10, 20, 50, 100, 200),

отношения price / SMA,

углы наклона,

факты пересечений (golden/death cross).

Осцилляторы и индикаторы:

RSI,

Stochastic,

MACD (по необходимости),

индикаторы перекупленности/перепроданности.

Волатильность и диапазоны:

дневной/часовой диапазон в процентах,

ATR,

стандартное отклонение доходностей.

Объёмы:

текущий объём / средний объём,

z-score объёма (аномально высокий/низкий).

Позиция цены:

позиция в дневном/недельном диапазоне (0–1),

расстояние до локальных максимумов/минимумов.

Свечной и структурный анализ (простые паттерны):

длинные тени,

поглощения,

гэпы,

иные базовые паттерны, определяемые алгоритмически.

3.2. Рыночные и секторные признаки

Индексы:

технические признаки, аналогичные бумаге, для IMOEX/RTSI,

изменение индексов за последние N периодов.

Сектора:

средняя доходность и волатильность по сектору,

позиция сектора в диапазоне,

корреляция бумаги с сектором и индексом.

3.3. Фундаментальные факторы (компактно)

Для каждой бумаги создавай агрегированные фундаментальные факторы, например:

fund_value_score — относительная “дешевизна/дороговизна” (по мультипликаторам),

fund_growth_score — динамика роста (выручка, прибыль),

fund_quality_score — устойчивость бизнеса, маржа, рентабельность,

fund_dividend_score — стабильность/уровень дивидендов,

fund_risk_score — долговая нагрузка, чувствительность к ставкам/регуляторике.

Эти факторы могут обновляться реже (по отчётностям, раз в квартал/месяц).

3.4. Новостные признаки

От модуля news-триггеров по каждой бумаге и времени:

news_trigger_score_t — численная сила события,

news_direction_t — знак воздействия (−1/0/+1),

news_event_type — категориальный признак (one-hot/embedding).

4. Целевые метки и постановка задач
4.1. Горизонты и торговая логика

Определи один или несколько горизонтов H:

Интрадей: ~1 час или до конца дня,

Swing: 3–10 дней,

Позиционный: 20–60 дней.

Для каждого горизонта задаётся базовая сделка:

Вход: P_in = Close(t) или ближайшая цена после сигнала.

Уровни:

TP (TakeProfit) в %, например +3..10%,

SL (StopLoss) в %, например −1..3%.

Окно анализа: [t+1, t+H].

4.2. Метки “успех сделки”

Для каждой точки (secid, t):

Определи вход P_in.

В окне [t+1, t+H] найди:

P_max (max high),

P_min (min low).

Для лонга:

если P_max >= TP до того, как P_min <= SL → label_long = 1,

иначе label_long = 0.

Для шорта (если поддерживается):

аналогично, но с инверсией логики.

Также вычисли:

фактический P&L для условной сделки,

MaxDrawdown_H, MaxUpside_H.

4.3. Что должна предсказывать модель (multitask)

Модель (или блок моделей) должна выдавать:

P_success_long — вероятность успешной лонг-сделки.

P_success_short — вероятность успешной шорт-сделки (может быть опциональной).

R_H — ожидаемая доходность за горизонт H.

Vol_H — ожидаемая волатильность/просадка за горизонт H.

direction_class — класс движения:

сильный рост / умеренный рост / флэт / умеренное падение / сильное падение.

На основе этих выходов формируются:

сигналы BUY/SELL/HOLD/NO_TRADE,

размер и агрессивность входа,

уровни TP/SL.

5. Архитектура моделей
5.1. Глобальная временная модель

Реализуй основную нейросетевую модель временных рядов:

Возможные варианты:

Transformer для временных рядов,

Temporal Convolutional Network (TCN),

или LSTM/GRU с механизмом внимания.

Вход:

Окно из последних N шагов по конкретной бумаге:

технические признаки,

рыночные/секторные признаки,

новостные признаки,

фундаментальные факторы (как медленно меняющиеся фичи).

Выход:

весь набор целевых параметров (см. 4.3) — многозадачная модель.

5.2. Мульти-стратегический “совет директоров”

Сделай несколько стратегических голов (heads) или отдельных малых моделей:

strategy_trend — трендовая,

strategy_mean_reversion — контртрендовая,

strategy_news — новостная,

strategy_volatility — игра на волатильности.

Каждая голова:

получает те же признаки (или подмножество),

выдаёт:

свои P_success_long и P_success_short,

свои рекомендации по TP/SL (после обучения/калибровки).

Сделай агрегирующую meta-голову:

на вход: выходы стратегий + глобальной модели,

на выход: единый итоговый сигнал + итоговый confidence,

сохраняй "голоса" стратегий для объяснений.

5.3. Локальные адаптеры по тикерам

Для каждой бумаги secid:

реализуй облегчённый адаптер (например, XGBoost/LightGBM, MLP или простая линейная модель), который:

принимает:

выходы глобальной модели/стратегий по этой бумаге,

локальные фичи по бумаге (волатильность, ликвидность, уникальные паттерны),

корректирует:

вероятности успеха,

уровни TP/SL,

confidence.

Адаптеры:

обучаются/дообучаются по истории конкретной бумаги,

используют скользящее окно по времени (последние 6–12 месяцев),

обновляются с заданной периодичностью (например, раз в неделю/месяц),

проходят проверку на том, что новая версия не ухудшает P&L по сравнению с предыдущей на отложенном периоде.

6. Дополнительные модули «умного трейдера»
6.1. Детектор рыночного режима

Реализуй отдельный модуль, который классифицирует состояние рынка:

Вход:

индикаторы по основным индексам,

распределение доходностей по широкому списку бумаг,

волатильность рынка,

агрегированный новостной фон.

Выход:

market_regime ∈ {uptrend, downtrend, flat, panic, euphoria, news_storm}.

Использование:

воздействуй на пороги и агрессивность сигналов,

добавляй режим в текстовое объяснение пользователю.

6.2. Модуль сценариев и вероятностей

На основе предсказаний модели (R_H, Vol_H, классы движения):

формируй вероятностное распределение диапазонов цены на горизонте H:

“25% — цена останется в диапазоне 310–320”,

“50% — 320–340”,

“25% — ниже 305”.

Этот модуль выдаёт структуру сценариев, пригодную для отображения в интерфейсе.

6.3. Анализ портфеля пользователя

Модуль принимает:

список позиций пользователя:

[(secid, qty, avg_price, side), ...],

информацию о размере капитала/депозита (если доступна).

Функции модуля:

Для каждой позиции:

прогон через глобальную модель+адаптер,

рекомендация:

усилить / держать / сократить / закрыть,

краткое объяснение.

Для портфеля в целом:

расчёт:

долей по бумагам и секторам,

ожидаемой волатильности,

концентрации риска,

рекомендации:

по диверсификации,

по снижению сверхконцентрации.

6.4. Анти-тильт и поведенческий анализ

Модуль ведёт историю:

какие сигналы модель выдавала,

какие действия предпринял пользователь (по данным виртуального/реального портфеля):

следовал ли сигналу,

нарушал ли стопы,

открывал ли сделки без сигналов,

усреднял ли убыточные позиции,

частота сделок.

Функции:

В моменте:

если пользователь собирается открыть сделку с ненормально большим риском (по отношению к капиталу),

если действует против сильного сигнала модели в режиме “паника/эйфория”,

модуль генерирует “жёсткое предупреждение” и оценку возможного ущерба.

Периодические отчёты (например, раз в неделю):

статистика ошибок,

сравнение:

P&L по следованию сигналам,

P&L по “самодеятельности”,

персональные рекомендации.

6.5. Тренировочный режим «Ты vs AI-трейдер»

Реализуй сервис, который:

Выбирает исторический отрезок рынка и фиксированный момент времени t,

Формирует “срез” для пользователя:

график до t,

краткий описательный контекст (простые текстовые метки режима/новостей),

Пользователь выбирает:

BUY / SELL / HOLD / NO_TRADE,

Система:

рассчитывает, что сказали бы глобальная модель + адаптеры в точке t,

показывает, что произошло после t,

обновляет рейтинг пользователя по сравнению с моделью.

Со стороны ядра необходимы:

функция генерации тренировочного сценария,

функция оценки решения пользователя и выдачи итоговой статистики.

7. Обучение, валидация, дообучение
7.1. Разделение по времени

Делить данные на:

train — более старый период,

validation — средний период,

test — самый современный период.

Никаких перемешиваний по времени, избегать утечки будущего.

7.2. Метрики

Помимо стандартных ML-метрик:

Торговые метрики:

P&L по симуляции сигналов,

Sharpe ratio,

max drawdown,

win-rate,

средний профит/убыток на сделку,

соотношение среднего выигрыша к среднему проигрышу.

Модель и её модификации выбирать по комбинации ML-метрик и торговых метрик, с приоритетом у устойчивых торговых.

7.3. Пайплайн регулярного дообучения

Периодически (например, раз в неделю/месяц):

обновлять данные по свечам, фундаменталу (по мере выхода отчётности), новостям, сигналах и результатам сделок.

Обучение:

глобальную модель — реже (раз в месяц/квартал),

локальные адаптеры по тикерам — чаще (неделя/месяц).

Валидация новой версии:

сравнение P&L, drawdown, win-rate на отложенном периоде с предыдущей версией,

если новая модель хуже — не выкатывать, откатываться.

8. Сервисный слой / API для Miniapp

Реализуй REST-API (например FastAPI) со следующими основными эндпоинтами:

POST /analyze_ticker

Вход:

secid,

опционально: время/дата (или “сейчас”),

контекст пользователя (как минимум идентификатор).

Выход:

сигнал: BUY/SELL/HOLD/NO_TRADE,

диапазон входа, TP, SL,

confidence (0–100),

голоса стратегий,

рыночный режим,

сценарии цен с вероятностями,

текстовое объяснение.

POST /analyze_portfolio

Вход:

список позиций пользователя.

Выход:

рекомендации по каждой позиции,

анализ портфеля в целом,

предложения по перераспределению.

GET /market_heatmap

Выход:

список бумаг с текущими сигналами и их силой (для построения “тепловой карты”).

GET /training_scenario и POST /training_answer
Для тренировочного режима “Ты vs AI”.
GET /user_weekly_report
Возвращает сводку поведения и рекомендаций для пользователя.

9. Нефункциональные требования
Модульность:
отдельные модули для:
сбора данных,
feature engineering,
моделей,
обучения,
inference,
портфельного анализа,
поведенческого анализа,
API.
Конфигурируемость:
список тикеров,
таймфреймы,
горизонты H,
TP/SL,
частота дообучения — через конфиги.

Логирование:
логи входов/выходов модели,
логи ошибок,
логи метрик.

Возможность докеризации:
Dockerfile для сервиса,
docker-compose (или аналог) для БД + API + inference.

Следуй этому ТЗ.
Твоя задача — спроектировать, реализовать и подготовить инфраструктуру для обучения и эксплуатации такой нейросетевой системы AI-трейдера по Мосбирже, с доминирующим техническим анализом, расширенным фундаментальным слоем, модулями портфельного и поведенческого анализа, тренировочным режимом и возможностью интеграции в Telegram Miniapp через описанный API.
